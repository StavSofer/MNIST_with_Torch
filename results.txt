Old baseline - 3 layers, 20 epochs, 128 batchsize
without regularization
Training error: 0.0020532852564102	Training Loss: 0.00905050479401	
Test error: 0.024739583333333	Test Loss: 0.10000602060404

Baseline (3 layers, 20 epochs , 128 batchsize)
With regularization (default params)
Training error: 0.0073951655982906	Training Loss: 0.029671039611388	
Test error: 0.021634615384615	Test Loss: 0.069166142278566

Baseline (3 layers, 25 epochs , 128 batchsize)
With regularization (default params)
Training error: 0.0058426816239316	Training Loss: 0.024833695174983	
Test error: 0.020532852564103	Test Loss: 0.069239426547518	

Baseline (3 layers, 30 epochs , 128 batchsize)
With regularization (default params)
Training error: 0.0049746260683761	Training Loss: 0.023258564360917	
Test error: 0.021534455128205	Test Loss: 0.068900545772452	

From here Baseline = (3 layers, 25 epochs , 128 batchsize) With regularization (default params)

Baseline
SpatialLogSoftMax instead of LogSoftMax
Training error: 0.0057258279914529	Training Loss: 0.02482773630649	
Test error: 0.021734775641026	Test Loss: 0.065719016135121

Baseline
SpatialLogSoftMax instead of LogSoftMax
Sigmoid instead of RelU
Training error: 0.033603766025641	Training Loss: 0.13881605058813	
Test error: 0.036858974358974	Test Loss: 0.14672301432643	

Baseline
SpatialLogSoftMax instead of LogSoftMax
CrossEntropy instead of NLL
Training error: 0.0061765491452992	Training Loss: 0.026028968107242	
Test error: 0.021935096153846	Test Loss: 0.073313047058689

Baseline with batchsize = 256
SpatialLogSoftMax instead of LogSoftMax
CrossEntropy instead of NLL
Training error: 0.0081630608974359	Training Loss: 0.033665740126187	
Test error: 0.023137019230769	Test Loss: 0.075589008748722

Baseline with batchsize = 256
SpatialLogSoftMax instead of LogSoftMax
Training error: 0.0073116987179487	Training Loss: 0.03126636463512	
Test error: 0.022736378205128	Test Loss: 0.070075744022735

Baseline with batchsize = 64
SpatialLogSoftMax instead of LogSoftMax
Training error: 0.0081209978655283	Training Loss: 0.028346016708853	
Test error: 0.020833333333333	Test Loss: 0.06995903784170

Baseline with batchsize = 64
SpatialLogSoftMax instead of LogSoftMax
Tanh instead of RelU
Training error: 0.0076374066168623	Training Loss: 0.032676923193093	
Test error: 0.023036858974359	Test Loss: 0.075300955309127

Baseline with batchsize = 64
SpatialLogSoftMax instead of LogSoftMax
PReLU instead of RelU
Training error: 0.0060198772678762	Training Loss: 0.02125374544233	
Test error: 0.021935096153846	Test Loss: 0.077836876854492	

